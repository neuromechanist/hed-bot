name: Tests

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]
  workflow_dispatch:

jobs:
  lint:
    name: Lint & Format
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install linting tools
        run: |
          pip install ruff

      - name: Lint with Ruff
        run: ruff check src tests

      - name: Format check with Ruff
        run: ruff format --check src tests

  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.12']

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install dependencies
        run: |
          pip install -e ".[dev]"

      - name: Run unit tests (excluding integration)
        run: |
          pytest tests/ -v -m "not integration" --cov=src --cov-report=xml --cov-report=term-missing

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: ./coverage.xml
          flags: unittests
          name: codecov-unit
          fail_ci_if_error: false
          verbose: true

  integration-tests:
    name: Integration Tests (Real LLM)
    runs-on: ubuntu-latest
    # Only run integration tests on push (after merge) or manual trigger, not on PRs
    # This saves ~5-10 cents per run by avoiding LLM calls on every PR update
    if: github.event_name == 'push' || github.event_name == 'workflow_dispatch'

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          pip install -e ".[dev]"
          pip install pytest-timeout

      - name: Run all tests (unit + integration)
        env:
          OPENROUTER_API_KEY_FOR_TESTING: ${{ secrets.OPENROUTER_API_KEY_FOR_TESTING }}
        run: |
          # Only run if the secret is available
          if [ -n "$OPENROUTER_API_KEY_FOR_TESTING" ]; then
            echo "Running all tests (unit + integration) for combined coverage..."
            pytest tests/ -v --timeout=180 --cov=src --cov-report=xml --cov-report=term-missing
          else
            echo "OPENROUTER_API_KEY_FOR_TESTING not set, skipping integration tests"
          fi

      - name: Upload combined coverage to Codecov
        # Always upload coverage, even if some tests fail
        # This ensures partial coverage is still counted
        if: always()
        uses: codecov/codecov-action@v4
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: ./coverage.xml
          flags: combined
          name: codecov-combined
          fail_ci_if_error: false

  all-tests:
    name: All Tests Summary
    runs-on: ubuntu-latest
    needs: [lint, unit-tests, integration-tests]
    # Run even if integration-tests was skipped (on PRs)
    if: always()

    steps:
      - name: Check lint result
        if: needs.lint.result == 'failure'
        run: |
          echo "Lint check failed"
          exit 1

      - name: Check unit tests result
        if: needs.unit-tests.result == 'failure'
        run: |
          echo "Unit tests failed"
          exit 1

      - name: Check integration tests result
        # Only fail if integration tests ran and failed (not if skipped)
        if: needs.integration-tests.result == 'failure'
        run: |
          echo "Integration tests failed"
          exit 1

      - name: All checks passed
        run: |
          echo "All required checks passed!"
          echo "Lint: ${{ needs.lint.result }}"
          echo "Unit tests: ${{ needs.unit-tests.result }}"
          echo "Integration tests: ${{ needs.integration-tests.result }}"
