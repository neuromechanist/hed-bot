# ============================================================================
# HEDit Environment Configuration
# ============================================================================
# IMPORTANT: Do NOT use inline comments! Comments must be on their own line.
# WRONG:  API_KEYS=mykey  # this is my key
# RIGHT:  # This is my key
#         API_KEYS=mykey

# ============================================================================
# Security Configuration (REQUIRED for production)
# ============================================================================

# API Key Authentication
# Generate keys using: python scripts/generate_api_key.py
# Supports multiple keys (comma-separated)
API_KEYS=your-generated-api-key-here

# Set to "false" only for local development without auth
REQUIRE_API_AUTH=true

# BYOK (Bring Your Own Key) Mode
# When enabled, users can provide their own OpenRouter API key via X-OpenRouter-Key header
# Their key is used for LLM calls (billing goes to their account)
# Set to "false" to require server API keys only
ALLOW_BYOK=true

# Audit Logging (recommended for production)
ENABLE_AUDIT_LOG=true
AUDIT_LOG_FILE=/var/log/hedit/audit.log

# CORS Configuration
# Production frontend (hedit.pages.dev) is always allowed
# Localhost origins are allowed by default for testing
ALLOW_LOCALHOST_CORS=true

# Add extra origins here (comma-separated) if needed
# EXTRA_CORS_ORIGINS=https://example.com,https://other.com

# ============================================================================
# LLM Provider Configuration
# ============================================================================

# Provider: "openrouter" (recommended) or "ollama" (local GPU)
LLM_PROVIDER=openrouter

# Temperature: 0.0-1.0, lower = more consistent
LLM_TEMPERATURE=0.1

# ============================================================================
# OpenRouter Configuration (when LLM_PROVIDER=openrouter)
# ============================================================================

# Get your API key from https://openrouter.ai/
OPENROUTER_API_KEY=your-openrouter-api-key-here

# Test API key (separate key to track testing costs)
# Used only by integration tests that make real LLM calls
# OPENROUTER_API_KEY_FOR_TESTING=your-testing-api-key-here

# ============================================================================
# Model Configuration
# ============================================================================
# Each agent type has its own model and provider for optimal performance.

# Annotation Model (best quality/cost: Mistral-Small-3.2-24B)
# 100% faithful rate, $0.18/M output tokens
ANNOTATION_MODEL=mistralai/mistral-small-3.2-24b-instruct
ANNOTATION_PROVIDER=mistral

# Evaluation/Assessment Model (consistent quality checks: Qwen3-235B via Cerebras)
# Used for evaluation, assessment, and feedback agents
EVALUATION_MODEL=qwen/qwen3-235b-a22b-2507
EVALUATION_PROVIDER=Cerebras

# Vision Model (image description: Qwen3-VL via deepinfra)
VISION_MODEL=qwen/qwen3-vl-30b-a3b-instruct
VISION_PROVIDER=deepinfra/fp8

# ============================================================================
# Alternative Models
# ============================================================================
# For highest quality (but slower and more expensive):
# ANNOTATION_MODEL=openai/gpt-5.2
# ANNOTATION_PROVIDER=

# For fastest results:
# ANNOTATION_MODEL=anthropic/claude-haiku-4.5
# ANNOTATION_PROVIDER=

# ============================================================================
# Ollama Configuration (when LLM_PROVIDER=ollama)
# ============================================================================
# Only used if LLM_PROVIDER=ollama (local GPU deployment)
# LLM_BASE_URL=http://localhost:11435
# LLM_MODEL=qwen2.5:32b

# ============================================================================
# HED Configuration
# ============================================================================
HED_SCHEMA_VERSION=8.4.0

# ============================================================================
# HED-LSP Configuration (Recommended)
# ============================================================================
# HEDit can use hed-lsp CLI for HED tag suggestions.
# Install: git clone https://github.com/hed-standard/hed-lsp.git
#          cd hed-lsp/server && npm install && npm run compile && npm link
#
# Once installed, the 'hed-suggest' command will be available in PATH.
# HEDit auto-detects hed-lsp availability - no configuration needed!

# Enable semantic search for better tag suggestions (requires embeddings)
# HED_LSP_USE_SEMANTIC=false

# Maximum number of tag suggestions to return
# HED_LSP_MAX_RESULTS=10

# ============================================================================
# Legacy JavaScript Validator (Deprecated)
# ============================================================================
# NOTE: The JavaScript validator is deprecated in favor of hed-lsp.
# Only use if you need the legacy hed-javascript integration.
#
# NOTE: In Docker, paths are auto-detected. Do NOT set these unless you
# need to override (e.g., for local development outside Docker).
# Setting empty values will BREAK Docker deployment!

# Only uncomment if running locally outside Docker:
# HED_SCHEMA_DIR=/path/to/hed-schemas/schemas_latest_json
# HED_VALIDATOR_PATH=/path/to/hed-javascript

USE_JS_VALIDATOR=false

# ============================================================================
# API Configuration
# ============================================================================
API_HOST=0.0.0.0
API_PORT=38427
API_WORKERS=4

# ============================================================================
# Workflow Configuration
# ============================================================================
MAX_VALIDATION_ATTEMPTS=5
MAX_TOTAL_ITERATIONS=10

# ============================================================================
# Logging
# ============================================================================
LOG_LEVEL=INFO

# ============================================================================
# Feedback Processing (Optional)
# ============================================================================
# GitHub token for automatic issue creation from user feedback
# Required scopes: repo (for creating issues and comments)
# Get a token from: https://github.com/settings/tokens
# GITHUB_TOKEN=ghp_your-github-token-here

# Repository for feedback issues (defaults to Annotation-Garden/hedit)
# GITHUB_REPOSITORY_OWNER=Annotation-Garden
# GITHUB_REPOSITORY=hedit

# Feedback processing uses OPENROUTER_API_KEY_FOR_TESTING (if set) to track
# feedback-related LLM costs separately from annotation costs.
# Falls back to OPENROUTER_API_KEY if testing key is not set.
