# ============================================================================
# HEDit Environment Configuration
# ============================================================================
# IMPORTANT: Do NOT use inline comments! Comments must be on their own line.
# WRONG:  API_KEYS=mykey  # this is my key
# RIGHT:  # This is my key
#         API_KEYS=mykey

# ============================================================================
# Security Configuration (REQUIRED for production)
# ============================================================================

# API Key Authentication
# Generate keys using: python scripts/generate_api_key.py
# Supports multiple keys (comma-separated)
API_KEYS=your-generated-api-key-here

# Set to "false" only for local development without auth
REQUIRE_API_AUTH=true

# BYOK (Bring Your Own Key) Mode
# When enabled, users can provide their own OpenRouter API key via X-OpenRouter-Key header
# Their key is used for LLM calls (billing goes to their account)
# Set to "false" to require server API keys only
ALLOW_BYOK=true

# Audit Logging (recommended for production)
ENABLE_AUDIT_LOG=true
AUDIT_LOG_FILE=/var/log/hedit/audit.log

# CORS Configuration
# Production frontend (hedit.pages.dev) is always allowed
# Localhost origins are allowed by default for testing
ALLOW_LOCALHOST_CORS=true

# Add extra origins here (comma-separated) if needed
# EXTRA_CORS_ORIGINS=https://example.com,https://other.com

# ============================================================================
# LLM Provider Configuration
# ============================================================================

# Provider: "openrouter" (recommended) or "ollama" (local GPU)
LLM_PROVIDER=openrouter

# Temperature: 0.0-1.0, lower = more consistent
LLM_TEMPERATURE=0.1

# ============================================================================
# OpenRouter Configuration (when LLM_PROVIDER=openrouter)
# ============================================================================

# Get your API key from https://openrouter.ai/
OPENROUTER_API_KEY=your-openrouter-api-key-here

# Test API key (separate key to track testing costs)
# Used only by integration tests that make real LLM calls
# OPENROUTER_API_KEY_FOR_TESTING=your-testing-api-key-here

# Provider Preference - routes to specific infrastructure for speed
# Cerebras: Ultra-fast inference (~1-2s per annotation)
# Leave empty for default OpenRouter routing
LLM_PROVIDER_PREFERENCE=Cerebras

# Model Configuration (Cerebras-optimized defaults)
# These models work with Cerebras provider for maximum speed
ANNOTATION_MODEL=openai/gpt-oss-120b
EVALUATION_MODEL=qwen/qwen3-235b-a22b-2507
ASSESSMENT_MODEL=openai/gpt-oss-120b
FEEDBACK_MODEL=openai/gpt-oss-120b

# ============================================================================
# Alternative: OpenAI Models (if not using Cerebras)
# ============================================================================
# Uncomment these and set LLM_PROVIDER_PREFERENCE= (empty) to use OpenAI
# ANNOTATION_MODEL=gpt-4o-mini
# EVALUATION_MODEL=gpt-4o-mini
# ASSESSMENT_MODEL=gpt-4o-mini
# FEEDBACK_MODEL=gpt-4o-mini

# ============================================================================
# Ollama Configuration (when LLM_PROVIDER=ollama)
# ============================================================================
# Only used if LLM_PROVIDER=ollama (local GPU deployment)
# LLM_BASE_URL=http://localhost:11435
# LLM_MODEL=qwen2.5:32b

# ============================================================================
# HED Configuration
# ============================================================================
# NOTE: In Docker, paths are auto-detected. Do NOT set these unless you
# need to override (e.g., for local development outside Docker).
# Setting empty values will BREAK Docker deployment!

# Only uncomment if running locally outside Docker:
# HED_SCHEMA_DIR=/path/to/hed-schemas/schemas_latest_json
# HED_VALIDATOR_PATH=/path/to/hed-javascript

HED_SCHEMA_VERSION=8.4.0
USE_JS_VALIDATOR=true

# ============================================================================
# API Configuration
# ============================================================================
API_HOST=0.0.0.0
API_PORT=38427
API_WORKERS=4

# ============================================================================
# Workflow Configuration
# ============================================================================
MAX_VALIDATION_ATTEMPTS=5
MAX_TOTAL_ITERATIONS=10

# ============================================================================
# Logging
# ============================================================================
LOG_LEVEL=INFO

# ============================================================================
# Feedback Processing (Optional)
# ============================================================================
# GitHub token for automatic issue creation from user feedback
# Required scopes: repo (for creating issues and comments)
# Get a token from: https://github.com/settings/tokens
# GITHUB_TOKEN=ghp_your-github-token-here

# Repository for feedback issues (defaults to Annotation-Garden/hedit)
# GITHUB_REPOSITORY_OWNER=Annotation-Garden
# GITHUB_REPOSITORY=hedit

# Feedback processing uses OPENROUTER_API_KEY_FOR_TESTING (if set) to track
# feedback-related LLM costs separately from annotation costs.
# Falls back to OPENROUTER_API_KEY if testing key is not set.
